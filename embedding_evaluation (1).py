# -*- coding: utf-8 -*-
"""embedding_evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b3SaQBXbh5Z8aDN3LKIeapwCgi-Puhpc
"""

import gensim
import random
import nltk
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

nltk.download('punkt')

df = pd.read_csv('EcritureInclusive_replaced.csv') #, sep=";")
df['2'] = df['2'].str.lower()

print(df['2'])

train_set = df['2'].values # 1st 80% of corpus 
#train_set = train_set[0: int(len(train_set) * 0.8)]

training_set = [nltk.word_tokenize(article) for article in train_set]

model = gensim.models.Word2Vec(training_set, min_count=1, vector_size=300)

# constructing gender space of which to later calculate the cosine similarity of words onto this. 
# more components to any of these pairs of words than just their gender, so combining their vector directions
# encodes a gender direction -- pairs are mostly a translation from those used in Bolukbasi et. al. 
# except for ils/elles and le/la for which there is no english gender pair equivalent

masculin = ['il', 'ils', 'homme', 'garçon', 'frère', 'fils', 'le', 'père', 'mec', 'mâle', 'jean']
feminin = ['elle', 'elles', 'femme', 'fille','sœur', 'fille', 'la', 'mère', 'meuf', 'femelle', 'marie']

def doPCA(pairs, embedding, num_components = 10):
    matrix = []
    for pair in pairs:
        center = (model.wv[pair[0]] + model.wv[pair[1]])/2
        matrix.append(model.wv[pair[0]] - center)
        matrix.append(model.wv[pair[1]] - center)
    matrix = np.array(matrix)
    pca = PCA(n_components = num_components)
    pca.fit(matrix)
    plt.bar(range(num_components), pca.explained_variance_ratio_)
    return pca

def doPCA_sampling(pairs, embedding, num_components = 10):
    matrix = []
    for pair in pairs:
        center = (model.wv[pair[0]] + model.wv[pair[1]])/2
        matrix.append(model.wv[pair[0]] - center)
        matrix.append(model.wv[pair[1]] - center)
    return np.array(matrix)

def doPCA_averaging(matrix, embedding, num_components = 10):
    pca = PCA(n_components = num_components)
    pca.fit(matrix)
    plt.bar(range(num_components), pca.explained_variance_ratio_)
    return pca

pairs = [["elle", "il"], ["femme", "homme"], ["fille", "garçon"], ['fille', 'fils'], ["sœur", "frère"], ["mère", "père"], ["meuf", "mec"], ["femelle", "mâle"], ["marie", "jean"], ['elle-même', 'lui-même']]
pca = doPCA(pairs, model)
espace_genre_x = pca.components_[0]
print(espace_genre_x)

total_matrix = np.zeros((20, 300))

for i in range(1000):
  red = []
  for j in range(10):
    a = random.choice(random.choice(training_set))
    b = random.choice(random.choice(training_set))
    red.append((a, b)) 
    
  matrix = doPCA_sampling(red, model)
  total_matrix += matrix


total_matrix = total_matrix / 1000
pca_random = doPCA_averaging(total_matrix, model)
print(pca.components_[0])

print(model.wv.similarity('homme', 'auteur'))
print(model.wv.similarity('femme', 'pomme'))

print(model.wv.similarity('femme', 'auteur'))

# PAIRS 
pairs_x = ["lui-même", "elle-même", "jean", "marie", "mâle", "femelle",  "mec", "meuf", "père", "mère", "frère", "sœur", 'fils', 'fille',  "garçon", "fille",  "homme", "femme", "il", "elle"]
cos_pairs = []
for mot in pairs_x:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  cos_pairs.append(cos_sim)
  print(mot, cos_sim)



pair_data = pd.DataFrame(cos_pairs,
                    index=pairs_x,
                    columns=['values'])
pair_data['values'].plot(kind='barh',
                    color=(pair_data['values'] > 0).map({True: 'r',
                                                    False: 'b'}))



cos_set = []
for voc in model.wv:
  b = voc
  cos_mean = np.dot(espace_genre_x, b)/np.linalg.norm(espace_genre_x)*np.linalg.norm(b)
  if cos_mean < 0:
    cos_mean = cos_mean * -1
  cos_set.append(cos_mean)

mean = np.mean(cos_set)
standard_deviation = np.me
print("mean")
print(mean)
print(standard_deviation)
agg_data = pd.DataFrame(aggregate,
                    index=labels,
                    columns=['values'])
agg_data['values'].plot(kind='barh',
                    color=(agg_data['values'] > 0).map({True: 'b',
                                                    False: 'r'}))

#MOTS EPICÈNES -- no distinction between masculine and feminine word forms
epicenes = ['vétérinaire', 'secrétaire', 'psychiatre', 'pilote', 'peintre', 'ministre', 'maire', 'juriste', 'juge', 'interne', 'guide', 'gendarme', 'géologue', 'dramaturge', 'diplomate', 'dentiste','commissaire', 'cinéaste', 'céramiste', 'capitaine', 'astronaute', 'artiste', 'architecte', 'activiste', 'accessoiriste']
cos_epicenes = []
for mot in epicenes:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  cos_epicenes.append(cos_sim)
  print(mot, cos_sim)



epicene_data = pd.DataFrame(cos_epicenes,
                    index=epicenes,
                    columns=['values'])
epicene_data['values'].plot(kind='barh',
                    color=(epicene_data['values'] > 0).map({True: 'r',
                                                    False: 'b'}))

# profession pairs where adding an e at the end is optional and recently added to language
neologismes = [ 'rapporteure', 'rapporteur', 'professeure', 'professeur', 'procureure', 'procureur', 'pasteure', 'pasteur', 'médecine', 'médecin', 'gouverneure', 'gouverneur', 'entrepreneure', 'entrepreneur', 'écrivaine', 'écrivain', 'docteure' , 'docteur', 'auteure', 'auteur']

cos_neologismes = []
for mot in neologismes:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  print(mot, cos_sim)
  cos_neologismes.append(cos_sim)



neologismes_data = pd.DataFrame(cos_neologismes,
                    index=neologismes,
                    columns=['values'])
neologismes_data['values'].plot(kind='barh',
                    color=(neologismes_data['values'] > 0).map({True: 'r',
                                                    False: 'b'}))

# Other nouns written that use concatenation of forms, observed in dataset 
#joueur·euse·s
inclusif = ['tou·te·s', 'tous', 'invité·e·s', 'invités', 'opposant·es', 'opposants', 'ami·e·s', 'amis', 'habitant·es','habitants', 'salarié·e·s', 'salariés','professionnel·le·s', 'professionnels', 'guerrier·ère·s', 'guerriers', 'candidat·e·s','candidats', 'chercheur·e·s', 'chercheurs', 'étudiant·e·s',  'étudiants', 'lycéen·ne·s', 'lycéens', 'citoyen·ne·s', 'citoyens', 'auteur·es', 'auteurs'] #'chauffeurs', 'chauffeur·euse·s', 'jardiniers', 'jardinier·ière·s', 'lutteurs', 'lutteur·euse·s', 'musiciens', 'musicien·ne·s', 'arméniens', 'agriculteurs', 'agriculteur·rice·s', 'amateurs', 'amateur·rice·s', 'chanteurs', 'chanteur·euse·s', 'chauffeurs', 'chauffeur·euse·s', 'danseurs', 'danseur·euse·s', 'enseignants', 'enseignant·e·s', 'glaneurs', 'glaneur·euse·s', 'héritiers', 'héritier·ière·s', 'immigrants', 'immigrant·e·s', 'lecteurs', 'lecteur·rice·s', 'lutteurs', 'lutteur·euse·s', 'ouvriers', 'ouvrier·ière·s', 'producteurs', 'producteur·rice·s', 'travailleurs', 'travailleur·euse·s', 'électeurs', 'électeur·rice·s']
cos_inclusif = []
for mot in inclusif:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  print(mot, cos_sim)
  cos_inclusif.append(cos_sim)


inclusif_data = pd.DataFrame(cos_inclusif,
                    index=inclusif,
                    columns=['values'])

inclusif_data['values'].plot(kind='barh',
                    color=(inclusif_data['values'] > 0).map({True: 'r',
                                                    False: 'b'}))

#inclusif 2
two_inclusif = ['chauffeur·euse·s', 'chauffeurs','jardinier·ière·s',  'jardiniers', 'lutteur·euse·s', 'lutteurs', 'musicien·ne·s', 'musiciens', 'agriculteur·rice·s', 'agriculteurs', 'amateur·rice·s', 'amateurs',  'chanteur·euse·s', 'chanteurs', 'chauffeur·euse·s', 'chauffeurs',  'danseur·euse·s', 'danseurs', 'enseignant·e·s', 'enseignants', 'glaneur·euse·s', 'glaneurs', 'héritier·ière·s', 'héritiers', 'immigrant·e·s', 'immigrants', 'lecteur·rice·s', 'lecteurs', 'lutteur·euse·s', 'lutteurs', 'ouvrier·ière·s', 'ouvriers', 'producteur·rice·s', 'producteurs', 'travailleur·euse·s', 'travailleurs',  'électeur·rice·s', 'électeurs',]
cos_two = []
for mot in two_inclusif:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  print(mot, cos_sim)
  cos_two.append(cos_sim)


two_data = pd.DataFrame(cos_two,
                    index=two_inclusif,
                    columns=['values'])

two_data['values'].plot(kind='barh',
                    color=(two_data['values'] > 0).map({True: 'r',
                                                    False: 'b'}))

# Other nouns written that use concatenation of forms, observed in dataset 
#joueur·euse·s
nationalities = ['vénitien·ne·s', 'vénitiens', 'québécois·e·s', 'québécois', 'parisien·ne·s', 'parisiens', 'lyonnais·e·s', 'lyonnais',  'italien·ne·s', 'italiens', 'iranien·ne·s', 'iraniens', 'haïtien·ne·s', 'haïtiens', 'français·e·s', 'français', 'canadien·ne·s', 'canadiens', 'brésilien·ne·s', 'brésiliens', 'arménien·ne·s', 'arméniens']
cos_nationalities = []
for mot in nationalities:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  print(mot, cos_sim)
  cos_nationalities.append(cos_sim)


nationalities_data = pd.DataFrame(cos_nationalities,
                    index=nationalities,
                    columns=['values'])

nationalities_data['values'].plot(kind='barh',
                    color=(nationalities_data['values'] > 0).map({True: 'r',
                                                    False: 'b'}))

# Other nouns written that use concatenation of forms, observed in dataset 
#joueur·euse·s
plural_nationalities = ['brésilien', 'canadien', 'français', 'québécois', 'arménien', 'haïtien', 'iranien', 'italien', 'lyonnais',  'parisien', 'vénitien', 'brésiliens', 'canadiens', 'français', 'québécois', 'arméniens', 'haïtiens', 'iraniens', 'italiens', 'lyonnais',  'parisiens', 'vénitien']
cos_plural = []
for mot in plural_nationalities:
  b = model.wv[mot]
  cos_sim = np.dot(espace_genre_x, b)/(np.linalg.norm(espace_genre_x)*np.linalg.norm(b))
  print(mot, cos_sim)
  cos_nationalities.append(cos_sim)


plural_data = pd.DataFrame(cos_plural,
                    index=plural_nationalities,
                    columns=['values'])

plural_data['values'].plot(kind='barh',
                    color=(plural_data['values'] > 0).map({True: 'b',
                                                    False: 'r'}))

def text_plot_words(xs, ys, words, width = 90, height = 40, filename=None):
    PADDING = 10 # num chars on left and right in case words spill over
    res = [[' ' for i in range(width)] for j in range(height)]
    def rescale(nums):
        a = min(nums)
        b = max(nums)
        return [(x-a)/(b-a) for x in nums]
    print("x:", (min(xs), max(xs)), "y:",(min(ys),max(ys)))
    xs = rescale(xs)
    ys = rescale(ys)
    for (x, y, word) in zip(xs, ys, words):
        i = int(x*(width - 1 - PADDING))
        j = int(y*(height-1))
        row = res[j]
        z = list(row[i2] != ' ' for i2 in range(max(i-1, 0), min(width, i + len(word) + 1)))
        if any(z):
            continue
        for k in range(len(word)):
            if i+k>=width:
                break
            row[i+k] = word[k]
    string = "\n".join("".join(r) for r in res)
#     return string
    if filename:
        with open(filename, "w", encoding="utf8") as f:
            f.write(string)
        print("Wrote to", filename)
    else:
        print(string)

plt.scatter(epicenes, cos_epicenes)

for i, txt in enumerate(epicenes):
    ax.annotate(epicenes, (z[i], y[i]))

def display_pca_scatterplot(model, words=None):
    if words == None:
            words = [ word for word in model.vocab ]
        
    word_vectors = words #np.array([model.wv[w] for w in words])
    extra_dim = [espace_genre]
    twodim = PCA().fit_transform()[:,:2]
    
    plt.figure(figsize=(6,6))
    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')
    for word, (x,y) in zip(words, twodim):
        plt.text(x+0.05, y+0.05, word)

model.wv.most_similar(positive=['il','homme', 'garçon', 'frère', 'le', 'père', 'copain'], negative=['elle', 'femme', 'fille','sœur', 'la', 'mère', 'copine'], topn=20)

#vec = model['roi'] - model['homme'] + model['femme']
#print(model.wv.most_similar(vec))

model.wv['homme']

from google.colab import drive
drive.mount('/content/drive')